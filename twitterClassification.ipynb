{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csang\\miniconda3\\envs\\NLPBASICS\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import list_datasets\n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csang\\AppData\\Local\\Temp\\ipykernel_28676\\3505647632.py:1: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
      "  all_datasets = list_datasets()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derzeit sind 140841 Datensätze auf dem Hugging Face Hub verfügbar\n",
      "Die ersten 10 Datensätze sind: ['acronym_identification', 'ade_corpus_v2', 'UCLNLP/adversarial_qa', 'aeslc', 'afrikaans_ner_corpus', 'ag_news', 'allenai/ai2_arc', 'air_dialogue', 'ajgt_twitter_ar', 'allegro_reviews']\n"
     ]
    }
   ],
   "source": [
    "all_datasets = list_datasets()\n",
    "print(f\"Derzeit sind {len(all_datasets)} Datensätze auf dem Hugging Face Hub verfügbar\")\n",
    "print(f\"Die ersten 10 Datensätze sind: {all_datasets[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csang\\miniconda3\\envs\\NLPBASICS\\Lib\\site-packages\\datasets\\load.py:1486: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 3.97k/3.97k [00:00<?, ?B/s]\n",
      "Downloading metadata: 100%|██████████| 3.28k/3.28k [00:00<?, ?B/s]\n",
      "Downloading readme: 100%|██████████| 8.78k/8.78k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 592k/592k [00:00<00:00, 10.4MB/s]\n",
      "Downloading data: 100%|██████████| 74.0k/74.0k [00:00<00:00, 9.33MB/s]\n",
      "Downloading data: 100%|██████████| 74.9k/74.9k [00:00<00:00, 3.27MB/s]\n",
      "Generating train split: 100%|██████████| 16000/16000 [00:00<00:00, 101918.83 examples/s]\n",
      "Generating validation split: 100%|██████████| 2000/2000 [00:00<00:00, 63468.80 examples/s]\n",
      "Generating test split: 100%|██████████| 2000/2000 [00:00<00:00, 63390.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = load_dataset(\"emotion\")\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = emotions[\"train\"]\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Datensatz enthält 16000 Beispiele\n",
      "Das erste Beispiel ist: {'text': 'i didnt feel humiliated', 'label': 0}\n",
      "Colums: ['text', 'label']\n",
      "Features: {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}\n"
     ]
    }
   ],
   "source": [
    "len(train_ds)\n",
    "print(f\"Der Datensatz enthält {len(train_ds)} Beispiele\")\n",
    "print(f\"Das erste Beispiel ist: {train_ds[0]}\")\n",
    "print(f\"Colums: {train_ds.column_names}\")\n",
    "print(f\"Features: {train_ds.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die ersten 5 Beispiele sind: {'text': ['i didnt feel humiliated', 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'im grabbing a minute to post i feel greedy wrong', 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'i am feeling grouchy'], 'label': [0, 0, 3, 2, 3]}\n",
      "Die ersten 5 Labels sind: [0, 0, 3, 2, 3]\n",
      "Die ersten 5 Texte sind: ['i didnt feel humiliated', 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'im grabbing a minute to post i feel greedy wrong', 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'i am feeling grouchy']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Die ersten 5 Beispiele sind: {train_ds[:5]}\")\n",
    "print(f\"Die ersten 5 Labels sind: {train_ds['label'][:5]}\")\n",
    "print(f\"Die ersten 5 Texte sind: {train_ds['text'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions.set_format(type=\"pandas\")\n",
    "df = emotions[\"train\"][:]\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPBASICS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
